# Final-Project

Abstractive summarization is the task of generating a short summary that captures the salient ideas of the source text. The generated summaries potentially contain new phrases and sentences that may not appear in the source text. This differs from extractive summarization, which selects the most important sentences from the original text without modifying them.

![alt text](https://private-user-images.githubusercontent.com/122188963/290215356-feaa1c0e-bb41-4a31-aabc-809c33319e6a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTI1MDgwMDAsIm5iZiI6MTcxMjUwNzcwMCwicGF0aCI6Ii8xMjIxODg5NjMvMjkwMjE1MzU2LWZlYWExYzBlLWJiNDEtNGEzMS1hYWJjLTgwOWMzMzMxOWU2YS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNDA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDQwN1QxNjM1MDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wNGE4MmM3YjBmMTZmYzYyNzNkZmZjNDcwODkzYjIzM2Y2NWRiNTk0NjFiNjg1ZGUwMWM0Zjk0MDNjNGFjMGVjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.drpTuQMoUsWSqpZEyL2hmWZnO0SJuJRO7z56PAplVsw)

# Meet the T5 Transformer

T5 stands for Text-to-Text Transfer Transformer, which is a neural network model that can handle various natural language processing tasks by converting both the input and the output into text. For example, T5 can perform translation by taking a sentence in one language as input and producing a sentence in another language as output. Similarly, T5 can perform abstractive summarization by taking a long document as input and producing a summary as output.
The complete article with code and results can be found on Medium
